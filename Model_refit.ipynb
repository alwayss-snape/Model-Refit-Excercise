{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data created and split into train and test sets.\n",
      "Train set shape: (700, 20)\n",
      "Test set shape: (300, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create synthetic dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 20\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.random.randint(0, 2, n_samples)\n",
    "# Create a DataFrame\n",
    "feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Split into train and test sets (70:30 ratio)\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop(columns=['target']).values\n",
    "y_train = train_df['target'].values\n",
    "X_test = test_df.drop(columns=['target']).values\n",
    "y_test = test_df['target'].values\n",
    "\n",
    "print(\"Sample data created and split into train and test sets.\")\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-0.990737</td>\n",
       "      <td>-0.064204</td>\n",
       "      <td>-1.573629</td>\n",
       "      <td>0.372081</td>\n",
       "      <td>-1.115247</td>\n",
       "      <td>-0.278310</td>\n",
       "      <td>-0.372064</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>-0.552791</td>\n",
       "      <td>-0.595306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284567</td>\n",
       "      <td>-0.561051</td>\n",
       "      <td>-0.250834</td>\n",
       "      <td>1.645355</td>\n",
       "      <td>-0.235165</td>\n",
       "      <td>-0.689277</td>\n",
       "      <td>-0.684996</td>\n",
       "      <td>-0.549126</td>\n",
       "      <td>-0.594498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.815910</td>\n",
       "      <td>-1.153706</td>\n",
       "      <td>0.496635</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>0.400170</td>\n",
       "      <td>-2.014063</td>\n",
       "      <td>-0.866885</td>\n",
       "      <td>-0.029689</td>\n",
       "      <td>0.487218</td>\n",
       "      <td>0.767307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330784</td>\n",
       "      <td>0.084865</td>\n",
       "      <td>0.685619</td>\n",
       "      <td>0.312866</td>\n",
       "      <td>0.065738</td>\n",
       "      <td>-0.268369</td>\n",
       "      <td>0.081291</td>\n",
       "      <td>0.484591</td>\n",
       "      <td>0.267475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-1.701140</td>\n",
       "      <td>0.374062</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>0.063702</td>\n",
       "      <td>-0.216827</td>\n",
       "      <td>-0.292758</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>-0.028817</td>\n",
       "      <td>0.314972</td>\n",
       "      <td>0.214983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676994</td>\n",
       "      <td>0.192862</td>\n",
       "      <td>1.518422</td>\n",
       "      <td>0.420269</td>\n",
       "      <td>1.304963</td>\n",
       "      <td>0.606943</td>\n",
       "      <td>-1.841919</td>\n",
       "      <td>1.304835</td>\n",
       "      <td>0.135176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>-0.795655</td>\n",
       "      <td>1.399418</td>\n",
       "      <td>-0.236537</td>\n",
       "      <td>-1.311549</td>\n",
       "      <td>0.188073</td>\n",
       "      <td>-0.851180</td>\n",
       "      <td>0.665335</td>\n",
       "      <td>2.209606</td>\n",
       "      <td>-0.786572</td>\n",
       "      <td>0.332372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453905</td>\n",
       "      <td>-0.885714</td>\n",
       "      <td>-0.624835</td>\n",
       "      <td>-1.101286</td>\n",
       "      <td>0.732151</td>\n",
       "      <td>1.007304</td>\n",
       "      <td>0.023385</td>\n",
       "      <td>-0.864427</td>\n",
       "      <td>1.589523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>-2.875773</td>\n",
       "      <td>-0.118208</td>\n",
       "      <td>-0.007171</td>\n",
       "      <td>-2.482544</td>\n",
       "      <td>1.924838</td>\n",
       "      <td>0.286016</td>\n",
       "      <td>-0.849023</td>\n",
       "      <td>1.465379</td>\n",
       "      <td>-1.795613</td>\n",
       "      <td>-1.229171</td>\n",
       "      <td>...</td>\n",
       "      <td>1.801045</td>\n",
       "      <td>0.332346</td>\n",
       "      <td>0.659402</td>\n",
       "      <td>0.301001</td>\n",
       "      <td>0.573768</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>0.270921</td>\n",
       "      <td>0.107603</td>\n",
       "      <td>-0.608592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2.412615</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.262891</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.547119</td>\n",
       "      <td>-1.180813</td>\n",
       "      <td>1.114322</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.718186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019617</td>\n",
       "      <td>0.672861</td>\n",
       "      <td>0.591814</td>\n",
       "      <td>-0.354041</td>\n",
       "      <td>-0.573602</td>\n",
       "      <td>0.101856</td>\n",
       "      <td>1.549020</td>\n",
       "      <td>-1.239107</td>\n",
       "      <td>-1.467525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-1.187765</td>\n",
       "      <td>-0.397323</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>-0.851540</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-1.531535</td>\n",
       "      <td>1.150267</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>1.118550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523576</td>\n",
       "      <td>-0.764187</td>\n",
       "      <td>0.876174</td>\n",
       "      <td>-0.709431</td>\n",
       "      <td>0.644595</td>\n",
       "      <td>-0.382452</td>\n",
       "      <td>-1.975963</td>\n",
       "      <td>-0.570314</td>\n",
       "      <td>-1.179108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>-1.025943</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>-1.334827</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>1.636105</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>-0.923119</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062514</td>\n",
       "      <td>1.041108</td>\n",
       "      <td>0.653008</td>\n",
       "      <td>2.484144</td>\n",
       "      <td>1.192477</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.677150</td>\n",
       "      <td>-0.202443</td>\n",
       "      <td>-1.127504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1.592025</td>\n",
       "      <td>-0.587738</td>\n",
       "      <td>-1.443201</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>1.744311</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>1.414841</td>\n",
       "      <td>-0.874199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452690</td>\n",
       "      <td>-1.167865</td>\n",
       "      <td>-0.328375</td>\n",
       "      <td>1.107721</td>\n",
       "      <td>0.566602</td>\n",
       "      <td>0.644311</td>\n",
       "      <td>0.146476</td>\n",
       "      <td>0.523324</td>\n",
       "      <td>-0.800590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>-0.822420</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867130</td>\n",
       "      <td>-0.658116</td>\n",
       "      <td>-0.303726</td>\n",
       "      <td>-1.345871</td>\n",
       "      <td>-0.819258</td>\n",
       "      <td>-0.476221</td>\n",
       "      <td>0.874389</td>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.193590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "541  -0.990737  -0.064204  -1.573629   0.372081  -1.115247  -0.278310   \n",
       "440  -0.815910  -1.153706   0.496635   0.635100   0.400170  -2.014063   \n",
       "482  -1.701140   0.374062   0.264482   0.063702  -0.216827  -0.292758   \n",
       "422  -0.795655   1.399418  -0.236537  -1.311549   0.188073  -0.851180   \n",
       "778  -2.875773  -0.118208  -0.007171  -2.482544   1.924838   0.286016   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "106   2.412615   0.784604  -0.019260  -0.262891   0.022466   0.547119   \n",
       "270  -1.187765  -0.397323   0.534365   0.091094  -0.851540   0.006273   \n",
       "860   0.269784   0.011594  -1.025943   0.024647  -1.334827  -0.124077   \n",
       "435   1.592025  -0.587738  -1.443201   0.638187   1.744311   0.663598   \n",
       "102  -0.694713  -0.409282  -0.524088   0.152355  -0.822420   1.121031   \n",
       "\n",
       "     feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
       "541  -0.372064   0.280891  -0.552791  -0.595306  ...    0.284567   -0.561051   \n",
       "440  -0.866885  -0.029689   0.487218   0.767307  ...    0.330784    0.084865   \n",
       "482   0.501900  -0.028817   0.314972   0.214983  ...    0.676994    0.192862   \n",
       "422   0.665335   2.209606  -0.786572   0.332372  ...    0.453905   -0.885714   \n",
       "778  -0.849023   1.465379  -1.795613  -1.229171  ...    1.801045    0.332346   \n",
       "..         ...        ...        ...        ...  ...         ...         ...   \n",
       "106  -1.180813   1.114322   0.715381   0.718186  ...    0.019617    0.672861   \n",
       "270  -1.531535   1.150267  -0.205284   1.118550  ...   -0.523576   -0.764187   \n",
       "860   1.636105   0.822859  -0.923119  -0.072429  ...   -0.062514    1.041108   \n",
       "435   0.204798   0.409141   1.414841  -0.874199  ...   -0.452690   -1.167865   \n",
       "102   0.000207  -0.009300  -0.327895   0.155191  ...   -0.867130   -0.658116   \n",
       "\n",
       "     feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
       "541   -0.250834    1.645355   -0.235165   -0.689277   -0.684996   -0.549126   \n",
       "440    0.685619    0.312866    0.065738   -0.268369    0.081291    0.484591   \n",
       "482    1.518422    0.420269    1.304963    0.606943   -1.841919    1.304835   \n",
       "422   -0.624835   -1.101286    0.732151    1.007304    0.023385   -0.864427   \n",
       "778    0.659402    0.301001    0.573768    0.078078    0.270921    0.107603   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "106    0.591814   -0.354041   -0.573602    0.101856    1.549020   -1.239107   \n",
       "270    0.876174   -0.709431    0.644595   -0.382452   -1.975963   -0.570314   \n",
       "860    0.653008    2.484144    1.192477    0.204000    0.677150   -0.202443   \n",
       "435   -0.328375    1.107721    0.566602    0.644311    0.146476    0.523324   \n",
       "102   -0.303726   -1.345871   -0.819258   -0.476221    0.874389    0.262561   \n",
       "\n",
       "     feature_19  target  \n",
       "541   -0.594498       0  \n",
       "440    0.267475       0  \n",
       "482    0.135176       0  \n",
       "422    1.589523       0  \n",
       "778   -0.608592       0  \n",
       "..          ...     ...  \n",
       "106   -1.467525       1  \n",
       "270   -1.179108       1  \n",
       "860   -1.127504       1  \n",
       "435   -0.800590       0  \n",
       "102    0.193590       1  \n",
       "\n",
       "[700 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0)\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    gbm = lgb.train(param, train_data)\n",
    "\n",
    "    y_pred = gbm.predict(X_test)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "\n",
    "    trial.set_user_attr(\"roc\", roc)\n",
    "    trial.set_user_attr(\"accuracy\", accuracy)\n",
    "\n",
    "    return roc, accuracy\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Extract the trials DataFrame\n",
    "df1 = study.trials_dataframe()\n",
    "print(\"Original columns from trials_dataframe():\", df1.columns)\n",
    "\n",
    "df1 = df1.drop(columns=['datetime_start', 'datetime_complete', 'state','system_attrs_nsga2:generation','values_0','values_1','duration'])\n",
    "df1 = df1.rename(columns={'user_attrs_accuracy': 'Accuracy', 'user_attrs_roc': 'ROC', 'number': 'iteration_no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.859399</td>\n",
       "      <td>0.820505</td>\n",
       "      <td>0.085721</td>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.455830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.662536</td>\n",
       "      <td>0.825930</td>\n",
       "      <td>0.067218</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.480478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.939293</td>\n",
       "      <td>0.940921</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.461535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.949307</td>\n",
       "      <td>0.057113</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.493047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.979765</td>\n",
       "      <td>0.604917</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.500357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.691024</td>\n",
       "      <td>0.697569</td>\n",
       "      <td>0.039291</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.483509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.747228</td>\n",
       "      <td>0.051862</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.475352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.835278</td>\n",
       "      <td>0.756117</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.488411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.942164</td>\n",
       "      <td>0.609065</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.498574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.710270</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.503075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.611763</td>\n",
       "      <td>0.672698</td>\n",
       "      <td>0.093756</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.452977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.915635</td>\n",
       "      <td>0.879601</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.492289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.709496</td>\n",
       "      <td>0.620673</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.482484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.913214</td>\n",
       "      <td>0.601535</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.483464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.614316</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.026655</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.493582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.607797</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.035658</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.495454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.938112</td>\n",
       "      <td>0.650378</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.495454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.706110</td>\n",
       "      <td>0.650956</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.503922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.728781</td>\n",
       "      <td>0.727027</td>\n",
       "      <td>0.017767</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.483063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.945348</td>\n",
       "      <td>0.959339</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.491442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.714159</td>\n",
       "      <td>0.836835</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.504947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.874241</td>\n",
       "      <td>0.695413</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.498395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.794974</td>\n",
       "      <td>0.735378</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.477313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.804311</td>\n",
       "      <td>0.633054</td>\n",
       "      <td>0.070288</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.496301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.893944</td>\n",
       "      <td>0.049656</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.498930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "0              0                 0.859399                 0.820505   \n",
       "1              1                 0.662536                 0.825930   \n",
       "2              2                 0.939293                 0.940921   \n",
       "3              3                 0.765926                 0.949307   \n",
       "4              4                 0.688867                 0.764791   \n",
       "5              5                 0.979765                 0.604917   \n",
       "6              6                 0.691024                 0.697569   \n",
       "7              7                 0.990831                 0.726617   \n",
       "8              8                 0.615100                 0.747228   \n",
       "9              9                 0.835278                 0.756117   \n",
       "10            10                 0.942164                 0.609065   \n",
       "11            11                 0.667839                 0.710270   \n",
       "12            12                 0.792415                 0.822695   \n",
       "13            13                 0.611763                 0.672698   \n",
       "14            14                 0.915635                 0.879601   \n",
       "15            15                 0.709496                 0.620673   \n",
       "16            16                 0.913214                 0.601535   \n",
       "17            17                 0.614316                 0.748884   \n",
       "18            18                 0.607797                 0.848269   \n",
       "19            19                 0.938112                 0.650378   \n",
       "20            20                 0.734381                 0.851979   \n",
       "21            21                 0.706110                 0.650956   \n",
       "22            22                 0.807997                 0.706362   \n",
       "23            23                 0.728781                 0.727027   \n",
       "24            24                 0.945348                 0.959339   \n",
       "25            25                 0.714159                 0.836835   \n",
       "26            26                 0.874241                 0.695413   \n",
       "27            27                 0.794974                 0.735378   \n",
       "28            28                 0.804311                 0.633054   \n",
       "29            29                 0.891297                 0.893944   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "0               0.085721                 8                 75  0.463333   \n",
       "1               0.067218                 9                 49  0.506667   \n",
       "2               0.037548                 7                 60  0.476667   \n",
       "3               0.057113                 7                 69  0.510000   \n",
       "4               0.025181                 4                 66  0.530000   \n",
       "5               0.031587                 6                 24  0.496667   \n",
       "6               0.039291                 9                 83  0.490000   \n",
       "7               0.053574                 4                 81  0.543333   \n",
       "8               0.051862                 6                 85  0.480000   \n",
       "9               0.014957                 8                 30  0.520000   \n",
       "10              0.093541                 5                 71  0.506667   \n",
       "11              0.092877                 3                 62  0.513333   \n",
       "12              0.013354                 3                 26  0.530000   \n",
       "13              0.093756                10                 20  0.476667   \n",
       "14              0.023561                 8                 31  0.520000   \n",
       "15              0.017261                 8                 59  0.490000   \n",
       "16              0.030199                 5                 36  0.503333   \n",
       "17              0.026655                10                 38  0.520000   \n",
       "18              0.035658                 7                 93  0.486667   \n",
       "19              0.011650                 6                 64  0.510000   \n",
       "20              0.030177                 3                 92  0.510000   \n",
       "21              0.011502                 5                 57  0.523333   \n",
       "22              0.031951                 3                 85  0.546667   \n",
       "23              0.017767                 8                 44  0.503333   \n",
       "24              0.016457                 9                 57  0.506667   \n",
       "25              0.024710                 6                 99  0.520000   \n",
       "26              0.036890                 9                 85  0.530000   \n",
       "27              0.023333                10                 60  0.480000   \n",
       "28              0.070288                 5                 81  0.510000   \n",
       "29              0.049656                 5                 53  0.520000   \n",
       "\n",
       "         ROC  \n",
       "0   0.455830  \n",
       "1   0.480478  \n",
       "2   0.461535  \n",
       "3   0.493047  \n",
       "4   0.520324  \n",
       "5   0.500357  \n",
       "6   0.483509  \n",
       "7   0.519923  \n",
       "8   0.475352  \n",
       "9   0.488411  \n",
       "10  0.498574  \n",
       "11  0.503075  \n",
       "12  0.542031  \n",
       "13  0.452977  \n",
       "14  0.492289  \n",
       "15  0.482484  \n",
       "16  0.483464  \n",
       "17  0.493582  \n",
       "18  0.495454  \n",
       "19  0.495454  \n",
       "20  0.531868  \n",
       "21  0.503922  \n",
       "22  0.530041  \n",
       "23  0.483063  \n",
       "24  0.491442  \n",
       "25  0.504947  \n",
       "26  0.498395  \n",
       "27  0.477313  \n",
       "28  0.496301  \n",
       "29  0.498930  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "12            12                 0.792415                 0.822695   \n",
       "20            20                 0.734381                 0.851979   \n",
       "22            22                 0.807997                 0.706362   \n",
       "4              4                 0.688867                 0.764791   \n",
       "7              7                 0.990831                 0.726617   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "12              0.013354                 3                 26  0.530000   \n",
       "20              0.030177                 3                 92  0.510000   \n",
       "22              0.031951                 3                 85  0.546667   \n",
       "4               0.025181                 4                 66  0.530000   \n",
       "7               0.053574                 4                 81  0.543333   \n",
       "\n",
       "         ROC  \n",
       "12  0.542031  \n",
       "20  0.531868  \n",
       "22  0.530041  \n",
       "4   0.520324  \n",
       "7   0.519923  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Creating df2 with top 5 iterations based on RoC\n",
    "df2 = df1.nlargest(5, 'ROC').sort_values(by='ROC', ascending=False)\n",
    "df2['params_num_leaves'] = df2['params_num_leaves'].astype(int)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Training models for top 5 iterations\n",
    "def train_model(params):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    model = lgb.train(params, train_data)\n",
    "    return model\n",
    "\n",
    "models = []\n",
    "for _, row in df2.iterrows():\n",
    "    params = {\n",
    "        'learning_rate': row['params_learning_rate'],\n",
    "        'num_leaves': int(row['params_num_leaves']),\n",
    "        'max_depth': int(row['params_max_depth']),\n",
    "        'feature_fraction': row['params_feature_fraction'],\n",
    "        'bagging_fraction': row['params_bagging_fraction'],\n",
    "        'objective': 'binary'\n",
    "    }\n",
    "    model = train_model(params)\n",
    "    models.append(model)\n",
    "\n",
    "print(\"Models trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.714472</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.790257</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.762402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.805263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.947075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "12            12                 0.792415                 0.822695   \n",
       "20            20                 0.734381                 0.851979   \n",
       "22            22                 0.807997                 0.706362   \n",
       "4              4                 0.688867                 0.764791   \n",
       "7              7                 0.990831                 0.726617   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "12              0.013354                 3                 26  0.530000   \n",
       "20              0.030177                 3                 92  0.510000   \n",
       "22              0.031951                 3                 85  0.546667   \n",
       "4               0.025181                 4                 66  0.530000   \n",
       "7               0.053574                 4                 81  0.543333   \n",
       "\n",
       "         ROC  f1_score    recall precision  \n",
       "12  0.542031  0.714472  0.769663  0.666667  \n",
       "20  0.531868  0.790257  0.820225  0.762402  \n",
       "22  0.530041  0.791269  0.814607  0.769231  \n",
       "4   0.520324  0.831522  0.859551  0.805263  \n",
       "7   0.519923  0.951049  0.955056  0.947075  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Calculating additional metrics for each model\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "# Initialize the new columns in final_df\n",
    "final_df = df2.copy()\n",
    "final_df['f1_score'] = None\n",
    "final_df['recall'] = None\n",
    "final_df['precision'] = None\n",
    "\n",
    "# Iterate over the models and calculate the metrics\n",
    "for i, (index, row) in enumerate(df2.iterrows()):\n",
    "    model = models[i]\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred_class = (y_pred > 0.5).astype(int)\n",
    "    final_df.at[index, 'f1_score'] = f1_score(y_train, y_pred_class)\n",
    "    final_df.at[index, 'recall'] = recall_score(y_train, y_pred_class)\n",
    "    final_df.at[index, 'precision'] = precision_score(y_train, y_pred_class)\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>cumulative_capture_top_3_Deciles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.714472</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>45.786517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.790257</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.762402</td>\n",
       "      <td>55.05618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>53.370787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>54.775281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>58.988764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "12            12                 0.792415                 0.822695   \n",
       "20            20                 0.734381                 0.851979   \n",
       "22            22                 0.807997                 0.706362   \n",
       "4              4                 0.688867                 0.764791   \n",
       "7              7                 0.990831                 0.726617   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "12              0.013354                 3                 26  0.530000   \n",
       "20              0.030177                 3                 92  0.510000   \n",
       "22              0.031951                 3                 85  0.546667   \n",
       "4               0.025181                 4                 66  0.530000   \n",
       "7               0.053574                 4                 81  0.543333   \n",
       "\n",
       "         ROC  f1_score    recall precision cumulative_capture_top_3_Deciles  \n",
       "12  0.542031  0.714472  0.769663  0.666667                        45.786517  \n",
       "20  0.531868  0.790257  0.820225  0.762402                         55.05618  \n",
       "22  0.530041  0.791269  0.814607  0.769231                        53.370787  \n",
       "4   0.520324  0.831522  0.859551  0.805263                        54.775281  \n",
       "7   0.519923  0.951049  0.955056  0.947075                        58.988764  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Calculating cumulative capture for decile rank 7\n",
    "def calculate_cumulative_capture_decile_7(y_true, y_pred):\n",
    "    preds_df = pd.DataFrame({'pred': y_pred, 'actual': y_true})\n",
    "    preds_df['Decile_rank'] = pd.qcut(preds_df['pred'].rank(method='first'), 10, labels=False)\n",
    "    \n",
    "    responses = preds_df.groupby('Decile_rank', as_index=False).agg(\n",
    "        TOTAL_COUNT=('pred', 'count'),\n",
    "        TOTAL_ACTUAL=('actual', 'sum'),\n",
    "        MEAN_PROB=('pred', 'mean')\n",
    "    )\n",
    "    \n",
    "    responses[\"ACTUAL_RR\"] = (responses[\"TOTAL_ACTUAL\"] / responses[\"TOTAL_COUNT\"]) * 100\n",
    "    responses[\"%_ACTUAL_RC\"] = (responses[\"TOTAL_ACTUAL\"] / responses[\"TOTAL_ACTUAL\"].sum()) * 100\n",
    "    responses[\"CUMULATED_RC\"] = responses['%_ACTUAL_RC'][::-1].cumsum()[::-1]\n",
    "    \n",
    "    decile_7_cumulative = responses.loc[responses['Decile_rank'] == 7, 'CUMULATED_RC'].values\n",
    "    return decile_7_cumulative[0] if len(decile_7_cumulative) > 0 else None\n",
    "\n",
    "final_df['cumulative_capture_top_3_Deciles'] = None\n",
    "\n",
    "for i, (index, row) in enumerate(df2.iterrows()):\n",
    "    model = models[i]\n",
    "    y_pred = model.predict(X_train)\n",
    "    final_df.at[index, 'cumulative_capture_top_3_Deciles'] = calculate_cumulative_capture_decile_7(y_train, y_pred)\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>cumulative_capture_top_3_Deciles</th>\n",
       "      <th>decile_break</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.714472</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>45.786517</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.790257</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.762402</td>\n",
       "      <td>55.05618</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>53.370787</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>54.775281</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>58.988764</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "12            12                 0.792415                 0.822695   \n",
       "20            20                 0.734381                 0.851979   \n",
       "22            22                 0.807997                 0.706362   \n",
       "4              4                 0.688867                 0.764791   \n",
       "7              7                 0.990831                 0.726617   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "12              0.013354                 3                 26  0.530000   \n",
       "20              0.030177                 3                 92  0.510000   \n",
       "22              0.031951                 3                 85  0.546667   \n",
       "4               0.025181                 4                 66  0.530000   \n",
       "7               0.053574                 4                 81  0.543333   \n",
       "\n",
       "         ROC  f1_score    recall precision cumulative_capture_top_3_Deciles  \\\n",
       "12  0.542031  0.714472  0.769663  0.666667                        45.786517   \n",
       "20  0.531868  0.790257  0.820225  0.762402                         55.05618   \n",
       "22  0.530041  0.791269  0.814607  0.769231                        53.370787   \n",
       "4   0.520324  0.831522  0.859551  0.805263                        54.775281   \n",
       "7   0.519923  0.951049  0.955056  0.947075                        58.988764   \n",
       "\n",
       "   decile_break  \n",
       "12         None  \n",
       "20         None  \n",
       "22         None  \n",
       "4          None  \n",
       "7          None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Finding decile break\n",
    "def find_decile_break(y_true, y_pred):\n",
    "    preds_df = pd.DataFrame({'pred': y_pred, 'actual': y_true})\n",
    "    preds_df['Decile_rank'] = pd.qcut(preds_df['pred'].rank(method='first'), 10, labels=False)\n",
    "    \n",
    "    responses = preds_df.groupby('Decile_rank', as_index=False).agg(\n",
    "        TOTAL_COUNT=('pred', 'count'),\n",
    "        TOTAL_ACTUAL=('actual', 'sum')\n",
    "    )\n",
    "\n",
    "    responses[\"%_ACTUAL_RC\"] =(responses['TOTAL_ACTUAL']/responses[\"TOTAL_ACTUAL\"].sum())*100\n",
    "    \n",
    "    previous_value=None\n",
    "    decile_break = None\n",
    "    \n",
    "    for i in range(9,-1 -1): #iterate from decile 9 to 0\n",
    "        current_value = responses.at[i, '%_ACTUAL_RC']\n",
    "        if previous_value is not None and current_value>previous_value:\n",
    "            decile_break = i\n",
    "            break\n",
    "        previous_value=current_value\n",
    "\n",
    "    return decile_break\n",
    "\n",
    "final_df['decile_break'] = None\n",
    "\n",
    "for i,(index,row) in enumerate(df2.iterrows()):\n",
    "    model=models[i]\n",
    "    y_pred = model.predict(X_train)\n",
    "    final_df.at[index, 'decile_break'] = find_decile_break(y_train, y_pred)\n",
    "\n",
    "final_df=final_df.dropna(subset=['iteration_no'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_imp_var10</th>\n",
       "      <th>feature_imp_var11</th>\n",
       "      <th>feature_imp_var12</th>\n",
       "      <th>feature_imp_var13</th>\n",
       "      <th>feature_imp_var14</th>\n",
       "      <th>feature_imp_var15</th>\n",
       "      <th>feature_imp_var16</th>\n",
       "      <th>feature_imp_var17</th>\n",
       "      <th>feature_imp_var18</th>\n",
       "      <th>feature_imp_var19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.792415</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.714472</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>...</td>\n",
       "      <td>23.27%</td>\n",
       "      <td>1.37%</td>\n",
       "      <td>18.62%</td>\n",
       "      <td>2.28%</td>\n",
       "      <td>32.49%</td>\n",
       "      <td>26.54%</td>\n",
       "      <td>4.11%</td>\n",
       "      <td>4.40%</td>\n",
       "      <td>17.65%</td>\n",
       "      <td>22.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.851979</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.790257</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>...</td>\n",
       "      <td>20.69%</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>12.03%</td>\n",
       "      <td>10.47%</td>\n",
       "      <td>24.97%</td>\n",
       "      <td>26.13%</td>\n",
       "      <td>4.34%</td>\n",
       "      <td>3.34%</td>\n",
       "      <td>16.41%</td>\n",
       "      <td>14.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.807997</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.530041</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18%</td>\n",
       "      <td>2.97%</td>\n",
       "      <td>14.02%</td>\n",
       "      <td>9.10%</td>\n",
       "      <td>25.05%</td>\n",
       "      <td>24.06%</td>\n",
       "      <td>7.88%</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>9.15%</td>\n",
       "      <td>13.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.764791</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.520324</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>...</td>\n",
       "      <td>8.16%</td>\n",
       "      <td>2.83%</td>\n",
       "      <td>4.09%</td>\n",
       "      <td>3.41%</td>\n",
       "      <td>8.88%</td>\n",
       "      <td>10.88%</td>\n",
       "      <td>4.53%</td>\n",
       "      <td>1.87%</td>\n",
       "      <td>6.16%</td>\n",
       "      <td>5.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.053574</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.519923</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>...</td>\n",
       "      <td>16.31%</td>\n",
       "      <td>5.66%</td>\n",
       "      <td>8.18%</td>\n",
       "      <td>6.83%</td>\n",
       "      <td>17.75%</td>\n",
       "      <td>21.77%</td>\n",
       "      <td>9.06%</td>\n",
       "      <td>3.74%</td>\n",
       "      <td>12.32%</td>\n",
       "      <td>11.26%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration_no  params_bagging_fraction  params_feature_fraction  \\\n",
       "12          12.0                 0.792415                 0.822695   \n",
       "20          20.0                 0.734381                 0.851979   \n",
       "22          22.0                 0.807997                 0.706362   \n",
       "4            4.0                 0.688867                 0.764791   \n",
       "7            7.0                 0.990831                 0.726617   \n",
       "\n",
       "    params_learning_rate  params_max_depth  params_num_leaves  Accuracy  \\\n",
       "12              0.013354               3.0               26.0  0.530000   \n",
       "20              0.030177               3.0               92.0  0.510000   \n",
       "22              0.031951               3.0               85.0  0.546667   \n",
       "4               0.025181               4.0               66.0  0.530000   \n",
       "7               0.053574               4.0               81.0  0.543333   \n",
       "\n",
       "         ROC  f1_score    recall  ... feature_imp_var10 feature_imp_var11  \\\n",
       "12  0.542031  0.714472  0.769663  ...            23.27%             1.37%   \n",
       "20  0.531868  0.790257  0.820225  ...            20.69%             2.00%   \n",
       "22  0.530041  0.791269  0.814607  ...            21.18%             2.97%   \n",
       "4   0.520324  0.831522  0.859551  ...             8.16%             2.83%   \n",
       "7   0.519923  0.951049  0.955056  ...            16.31%             5.66%   \n",
       "\n",
       "   feature_imp_var12 feature_imp_var13 feature_imp_var14 feature_imp_var15  \\\n",
       "12            18.62%             2.28%            32.49%            26.54%   \n",
       "20            12.03%            10.47%            24.97%            26.13%   \n",
       "22            14.02%             9.10%            25.05%            24.06%   \n",
       "4              4.09%             3.41%             8.88%            10.88%   \n",
       "7              8.18%             6.83%            17.75%            21.77%   \n",
       "\n",
       "   feature_imp_var16 feature_imp_var17 feature_imp_var18 feature_imp_var19  \n",
       "12             4.11%             4.40%            17.65%            22.80%  \n",
       "20             4.34%             3.34%            16.41%            14.89%  \n",
       "22             7.88%             4.63%             9.15%            13.57%  \n",
       "4              4.53%             1.87%             6.16%             5.63%  \n",
       "7              9.06%             3.74%            12.32%            11.26%  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Adding feature importance as Gain percentages\n",
    "feature_names = [f'feature_imp_var{i}' for i in range(20)]\n",
    "\n",
    "# Initialize columns in final_df for feature importances as percentages\n",
    "for i, (index,row) in enumerate(df2.iterrows()):\n",
    "    model = models[i]\n",
    "    importance=model.feature_importance(importance_type='gain')\n",
    "    importance_percentage=(importance/importance.sum())*200\n",
    "\n",
    "    for j , feature in enumerate(feature_names):\n",
    "        final_df.at[index,feature] = f\"{importance_percentage[j]:.2f}%\"\n",
    "\n",
    "# Adding feature importance for each model as Gain percentages\n",
    "for i, model in enumerate(models):\n",
    "    importance = model.feature_importance(importance_type='gain')\n",
    "    importance_percentage = (importance / importance.sum()) * 100\n",
    "    for j, feature in enumerate(feature_names):\n",
    "        final_df.at[i, feature] = f\"{importance_percentage[j]:.2f}%\"\n",
    "final_df=final_df.dropna(subset=['iteration_no'])\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
